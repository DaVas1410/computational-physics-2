{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80cd4f5e",
   "metadata": {},
   "source": [
    "# Final Exam (part 3) - Computational Physics 2\n",
    "\n",
    "### Deadline: Friday 6 June 2025 (by 23h59)\n",
    "### Credits: 10 points\n",
    "\n",
    "### Please keep the structure provided below and submit an organised notebook with clear answers to each item.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b1c822",
   "metadata": {},
   "source": [
    "## 3. MPI Parallelisation of Molecular Dynamics Simulations\n",
    "\n",
    "In this problem, you will use **Message Passing Interface (MPI)** library to parallelise the execution of molecular dynamics simulations for different temperatures. The goal is to distribute the simulation of various temperatures across multiple MPI processes, significantly reducing the overall computational time.\n",
    "\n",
    "### Code:\n",
    "The reference (serial) script can be found here:\n",
    "\n",
    "https://github.com/wbandabarragan/computational-physics-2/blob/main/exams/thermostat.py\n",
    "\n",
    "**You should only modify the code below the indicated line:**\n",
    "\n",
    "`# Your MPI parallelization code should start here. Do not modify the code above.`\n",
    "\n",
    "The core simulation logic within the `run` function should remain untouched.\n",
    "\n",
    "### Tasks:\n",
    "\n",
    "Use the provided script (`diffusion.py`) to create a new version of the script (`diffusion_mpi.py`) that uses the `mpi4py` library to parallelise the simulation execution. Here are the specific requirements for your MPI implementation:\n",
    "\n",
    "**(a)** Set up a world communicator to distribute tasks among processes. Determine the rank of each process and the total number of processes.\n",
    "\n",
    "**(b)** Distribute a range of temperatures among the available MPI processes. Each process should be responsible for running the simulation at one or more unique temperatures.\n",
    "\n",
    "**(c)** Ensure proper initialization and finalization of the MPI environment. Cores should also send completion signals.\n",
    "\n",
    "**(d)** The root/master process (rank 0) should handle workload communications and collect the simulation results from all other processes.\n",
    "\n",
    "**(e)** For each simulated temperature, generate the `temperature-N_atoms.png` plot and the `traj-hydrogen-3D-N_atoms.dump` file. In addition the root/master process should:\n",
    "\n",
    "- Collect and present the combined results (i.e., a single plot with all the temperature curves).\n",
    "\n",
    "- Save the total execution time and the number of CPU cores used to a CSV file (`mpi_scaling.csv`). \n",
    "\n",
    "**(f)** Run the script with `mpirun` and different number of processors in an HPC facility.\n",
    "\n",
    "### Scaling and analysis:\n",
    "\n",
    "Report the simulation results (temperature plots and scaling) in this notebook:\n",
    "\n",
    "**(g)** After running the MPI code for various numbers of CPU cores (e.g., 1, 2, 4, 8, 16, etc.), use the data accumulated in the CSV file (`mpi_scaling.csv`) from multiple runs to:\n",
    "\n",
    "- Plot the observed speedup (e.g., $S_p = T_1 / T_p$, where $T_1$ is the execution time on 1 CPU and $T_p$ is the execution time on $p$ CPUs) as a function of the number of CPU cores.\n",
    "\n",
    "- Compare your observed speedup to Amdahl's Law and discuss any discrepancies between the observed and theoretical speedup."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
